{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2088da63",
   "metadata": {},
   "source": [
    "# Geospatial Image Classification with Deep Learning  \n",
    "## End‑to‑End Satellite Image Analysis using CNNs and Vision Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4a1e7",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [The Dataset](#The-Dataset)\n",
    "\n",
    "2. [Importing The Required Libraries and Data](#Importing-The-Required-Libraries-and-Data)\n",
    "    - [TensorFlow Environment Settings](#TensorFlow-Environment-Settings)\n",
    "    - [The Required Libraries](#The-Required-Libraries)\n",
    "    - [Set Random Seed for Reproducibility](#Set-Random-Seed-for-Reproducibility)\n",
    "    - [Check GPU Availability](#Check-GPU-Availability)\n",
    "    - [Define Data Folder Path](#Define-Data-Folder-Path)\n",
    "\n",
    "3. [Model Hyperparameters](#Model-Hyperparameters)\n",
    "\n",
    "4. [Create Image Data Generator for Data Augmentation](#Create-Image-Data-Generator-for-Data-Augmentation)\n",
    "\n",
    "5. [Create Training and Validation Generators](#Create-Training-and-Validation-Generators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f024b",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33cbc49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b0776a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36b1a384",
   "metadata": {},
   "source": [
    "## Importing The Required Libraries and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55991f1",
   "metadata": {},
   "source": [
    "### TensorFlow Environment Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852621d6",
   "metadata": {},
   "source": [
    "> Environment Variables:\n",
    "\n",
    "- `TF_ENABLE_ONEDNN_OPTS` \\\n",
    "Controls Intel oneDNN CPU optimizations in TensorFlow.\n",
    "  - `1` → enable optimized CPU kernels (default, faster)\n",
    "  - `0` → disable them (useful for reproducibility or avoiding numerical differences)\n",
    "\n",
    "- `TF_CPP_MIN_LOG_LEVEL` \\\n",
    "Controls how much TensorFlow logs to the console.\n",
    "  - `0` → show all logs  \n",
    "  - `1` → hide INFO  \n",
    "  - `2` → hide INFO + WARNING  \n",
    "  - `3` → show only errors  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229549c5",
   "metadata": {},
   "source": [
    "Environment variables must be set before TensorFlow loads, otherwise they have no effect. This ensures TensorFlow reads those settings during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e710cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87d409",
   "metadata": {},
   "source": [
    "### The Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6a6ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ecd96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Dense, Flatten, Dropout,\n",
    "    BatchNormalization, GlobalAveragePooling2D\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.initializers import HeUniform\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c595af35",
   "metadata": {},
   "source": [
    "### Set Random Seed for Reproducibility  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a63409",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 62\n",
    "random.seed(SEED) \n",
    "np.random.seed(SEED) \n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0c53db",
   "metadata": {},
   "source": [
    "### Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f1e55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for training: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"gpu\" if tf.config.list_physical_devices('GPU') else \"cpu\"\n",
    "print(\"Device available for training:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d883cb",
   "metadata": {},
   "source": [
    "### Define Data Folder Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca744cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder path: .\\data\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(\".\", \"data\") \n",
    "print(\"Data folder path:\", data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b86d4",
   "metadata": {},
   "source": [
    "## Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71506871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "img_w, img_h = 64, 64\n",
    "n_channels = 3\n",
    "\n",
    "batch_size = 128\n",
    "lr = 0.001          # Learning rate\n",
    "n_epochs = 3        # Adjust as needed\n",
    "\n",
    "steps_per_epoch = None\n",
    "validation_steps = None\n",
    "\n",
    "model_name = \"tf_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c64791",
   "metadata": {},
   "source": [
    "## Configure Image Data Generator for Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad54960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    # Convert pixel values from the range [0,255] to [0,1]\n",
    "    rescale= 1./255,\n",
    "    # Randomly rotate images by up to ±25 degrees \n",
    "    rotation_range= 25, \n",
    "    # Randomly shift the image horizontally by up to 15% of the width\n",
    "    width_shift_range= 0.15, \n",
    "    height_shift_range= 0.15, \n",
    "    # Apply a shearing transformation, like slanting the image\n",
    "    shear_range= 0.2,\n",
    "    # Randomly zoom in or out by up to 10%\n",
    "    zoom_range= 0.1, \n",
    "    # Randomly flip images left–right\n",
    "    horizontal_flip= True, \n",
    "    # Determine how to fill in new pixels created by rotations, shifts, or zooms\n",
    "    # \"nearest\" copies the value of the nearest pixel\n",
    "    fill_mode= \"nearest\",\n",
    "    validation_split= 0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a57e8e",
   "metadata": {},
   "source": [
    "## Create Training and Validation Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e4a5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4800 images belonging to 2 classes.\n",
      "Found 1200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size= (img_w, img_h),\n",
    "    batch_size= batch_size,\n",
    "    class_mode= \"binary\",\n",
    "    subset= \"training\",\n",
    "    shuffle= True,\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size= (img_w, img_h),\n",
    "    batch_size= batch_size,\n",
    "    class_mode= \"binary\",\n",
    "    subset= \"validation\",\n",
    "    shuffle= False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3526a0a1",
   "metadata": {},
   "source": [
    "> Why ``shuffle=True`` for training but ``shuffle=False`` for validation\n",
    "\n",
    "Shuffling is enabled for the training generator because the model should see \n",
    "the data in a different order in each epoch to improve generalization and to reduce overfitting, while the validation generator keeps ``shuffle=False`` so evaluation remains stable and deterministic. Even with a fixed seed, shuffling the validation set is still discouraged because the goal of validation is stable, repeatable evaluation. A seed only guarantees that the shuffle order is the same each run, but the order would still change every epoch.\n",
    "\n",
    "For ``flow_from_directory``, the default value of ``shuffle`` is ``True``."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
