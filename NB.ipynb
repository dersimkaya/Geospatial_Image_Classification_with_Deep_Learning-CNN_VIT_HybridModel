{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2088da63",
   "metadata": {},
   "source": [
    "# Geospatial Image Classification with Deep Learning  \n",
    "## End‑to‑End Satellite Image Analysis using CNNs and Vision Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4a1e7",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [The Dataset](#The-Dataset)\n",
    "\n",
    "2. [Importing The Required Libraries and Data](#Importing-The-Required-Libraries-and-Data)\n",
    "    - [TensorFlow Environment Settings](#TensorFlow-Environment-Settings)\n",
    "    - [The Required Libraries](#The-Required-Libraries)\n",
    "    - [Set Random Seed for Reproducibility](#Set-Random-Seed-for-Reproducibility)\n",
    "    - [Check GPU Availability](#Check-GPU-Availability)\n",
    "    - [Define Data Folder Path](#Define-Data-Folder-Path)\n",
    "\n",
    "3. [Model Hyperparameters](#Model-Hyperparameters)\n",
    "\n",
    "4. [Create Image Data Generator for Data Augmentation](#Create-Image-Data-Generator-for-Data-Augmentation)\n",
    "\n",
    "5. [Create Training and Validation Generators](#Create-Training-and-Validation-Generators)\n",
    "\n",
    "6. [Model Definition](#Model-Definition)\n",
    "\n",
    "7. [Model Compilation](#Model-Compilation)\n",
    "\n",
    "8. [Model Training](#Model-Training)\n",
    "\n",
    "9. []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f024b",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33cbc49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36b1a384",
   "metadata": {},
   "source": [
    "## Importing The Required Libraries and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55991f1",
   "metadata": {},
   "source": [
    "### TensorFlow Environment Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852621d6",
   "metadata": {},
   "source": [
    "> Environment Variables:\n",
    "\n",
    "- `TF_ENABLE_ONEDNN_OPTS` \\\n",
    "Controls Intel oneDNN CPU optimizations in TensorFlow.\n",
    "  - `1` → enable optimized CPU kernels (default, faster)\n",
    "  - `0` → disable them (useful for reproducibility or avoiding numerical differences)\n",
    "\n",
    "- `TF_CPP_MIN_LOG_LEVEL` \\\n",
    "Controls how much TensorFlow logs to the console.\n",
    "  - `0` → show all logs  \n",
    "  - `1` → hide INFO  \n",
    "  - `2` → hide INFO + WARNING  \n",
    "  - `3` → show only errors  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229549c5",
   "metadata": {},
   "source": [
    "Environment variables must be set before TensorFlow loads, otherwise they have no effect. This ensures TensorFlow reads those settings during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87d409",
   "metadata": {},
   "source": [
    "### The Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a6ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Dense, Flatten, Dropout,\n",
    "    BatchNormalization, GlobalAveragePooling2D\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.initializers import HeUniform\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c595af35",
   "metadata": {},
   "source": [
    "### Set Random Seed for Reproducibility  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a63409",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 62\n",
    "random.seed(SEED) \n",
    "np.random.seed(SEED) \n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0c53db",
   "metadata": {},
   "source": [
    "### Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f1e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"gpu\" if tf.config.list_physical_devices('GPU') else \"cpu\"\n",
    "print(\"Device available for training:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d883cb",
   "metadata": {},
   "source": [
    "### Define Data Folder Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca744cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\".\", \"data\") \n",
    "print(\"Data folder path:\", data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e03b68f",
   "metadata": {},
   "source": [
    "## Model Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aee216",
   "metadata": {},
   "source": [
    "Use a batch size that evenly divides the number of validation samples to prevent partial batches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d292086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "img_w, img_h = 64, 64\n",
    "n_channels = 3\n",
    "\n",
    "batch_size = 120\n",
    "lr = 1e-3           # Learning rate\n",
    "n_epochs = 20       # Adjust as needed\n",
    "\n",
    "model_name = \"tf_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c64791",
   "metadata": {},
   "source": [
    "## Configure Image Data Generator for Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    # Convert pixel values from the range [0,255] to [0,1]\n",
    "    rescale= 1./255,\n",
    "    # Randomly rotate images by up to ±25 degrees \n",
    "    rotation_range= 25, \n",
    "    # Randomly shift the image horizontally by up to 15% of the width\n",
    "    width_shift_range= 0.2, \n",
    "    height_shift_range= 0.2, \n",
    "    # Apply a shearing transformation, like slanting the image\n",
    "    shear_range= 0.2,\n",
    "    # Randomly zoom in or out by up to 20%\n",
    "    zoom_range= 0.2, \n",
    "    # Randomly flip images left–right\n",
    "    horizontal_flip= True, \n",
    "    vertical_flip= True,\n",
    "    # Determine how to fill in new pixels created by rotations, shifts, or zooms\n",
    "    # \"nearest\" copies the value of the nearest pixel\n",
    "    fill_mode= \"nearest\",\n",
    "    validation_split= 0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a57e8e",
   "metadata": {},
   "source": [
    "## Create Training and Validation Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e4a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size= (img_w, img_h),\n",
    "    batch_size= batch_size,\n",
    "    class_mode= \"binary\",  # \"categorical\" for multi-class\n",
    "    subset= \"training\",\n",
    "    shuffle= True,\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size= (img_w, img_h),\n",
    "    batch_size= batch_size,\n",
    "    class_mode= \"binary\",  # \"categorical\" for multi-class\n",
    "    subset= \"validation\",\n",
    "    shuffle= False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3526a0a1",
   "metadata": {},
   "source": [
    "> Why ``shuffle=True`` for training but ``shuffle=False`` for validation\n",
    "\n",
    "Shuffling is enabled for the training generator because the model should see \n",
    "the data in a different order in each epoch to improve generalization and to reduce overfitting, while the validation generator keeps ``shuffle=False`` so evaluation remains stable and deterministic. Even with a fixed seed, shuffling the validation set is still discouraged because the goal of validation is stable, repeatable evaluation. A seed only guarantees that the shuffle order is the same each run, but the order would still change every epoch.\n",
    "\n",
    "For ``flow_from_directory``, the default value of ``shuffle`` is ``True``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b883535",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(input_shape, num_classes= 1):\n",
    "    model = Sequential([\n",
    "        # --- Convolution Block 1 ---\n",
    "        Conv2D(32, \n",
    "               (5, 5), \n",
    "               activation= \"relu\", \n",
    "               padding= \"same\",\n",
    "               strides= (1, 1), \n",
    "               kernel_initializer= HeUniform(),\n",
    "               input_shape= input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        # --- Convolution Block 2 ---\n",
    "        Conv2D(64, \n",
    "               (5, 5), \n",
    "               activation=\"relu\", \n",
    "               padding= \"same\",\n",
    "               strides= (1, 1), \n",
    "               kernel_initializer= HeUniform()),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        # --- Convolution Block 3 ---\n",
    "        Conv2D(128, \n",
    "               (5, 5), \n",
    "               activation= \"relu\", \n",
    "               padding= \"same\",\n",
    "               strides= (1, 1), \n",
    "               kernel_initializer= HeUniform()),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        # --- Convolution Block 4 ---\n",
    "        Conv2D(256, \n",
    "               (5, 5), \n",
    "               activation= \"relu\", \n",
    "               padding= \"same\",\n",
    "               strides= (1, 1), \n",
    "               kernel_initializer= HeUniform()),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        # --- Convolution Block 5 ---\n",
    "        Conv2D(512, \n",
    "               (5, 5), \n",
    "               activation= \"relu\", \n",
    "               padding= \"same\",\n",
    "               strides= (1, 1), \n",
    "               kernel_initializer= HeUniform()),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        # --- Convolution Block 6 ---\n",
    "        Conv2D(1024, \n",
    "               (5, 5), \n",
    "               activation= \"relu\", \n",
    "               padding= \"same\",\n",
    "               strides= (1, 1), \n",
    "               kernel_initializer= HeUniform()),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        # --- Global Pooling ---\n",
    "        GlobalAveragePooling2D(),\n",
    "\n",
    "        # --- Dense Block 1 ---\n",
    "        Dense(64, \n",
    "              activation= \"relu\", \n",
    "              kernel_initializer= HeUniform()),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        Dense(128, \n",
    "              activation= \"relu\", \n",
    "              kernel_initializer= HeUniform()),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        Dense(256, \n",
    "              activation= \"relu\", \n",
    "              kernel_initializer= HeUniform()),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        # --- Dense Block 2 ---\n",
    "        Dense(512, \n",
    "              activation= \"relu\", \n",
    "              kernel_initializer= HeUniform()),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        Dense(1024, \n",
    "              activation= \"relu\", \n",
    "              kernel_initializer= HeUniform()),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        Dense(2048, \n",
    "              activation= \"relu\", \n",
    "              kernel_initializer=HeUniform()),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        # --- Output Layer ---\n",
    "        Dense(num_classes, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331c326",
   "metadata": {},
   "source": [
    "## Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = build_cnn(\n",
    "    input_shape= (img_w, img_h, n_channels),\n",
    "    num_classes= 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_fn = \"binary_crossentropy\"\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer= Adam(learning_rate= lr),\n",
    "    loss= loss_fn,\n",
    "    metrics= [\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb741b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_layers = len(model.layers)\n",
    "\n",
    "print(\"Total layers:\", len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc06409c",
   "metadata": {},
   "source": [
    ">**Layers with no parameters** \n",
    "\n",
    "- MaxPooling\n",
    "\n",
    "- GlobalAveragePooling\n",
    "\n",
    "- Dropout\n",
    "\n",
    "- Activation layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bba2c3",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83237f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps per epoch \n",
    "steps_per_epoch = train_generator.samples // batch_size\n",
    "validation_steps = val_generator.samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f09c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stop = EarlyStopping(\n",
    "    monitor= \"val_loss\",\n",
    "    patience= 8,\n",
    "    restore_best_weights= True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor= \"val_loss\",\n",
    "    factor= 0.2,\n",
    "    patience= 5,\n",
    "    min_lr= 1e-6,\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath= model_name + \".keras\",\n",
    "    monitor= \"val_loss\",\n",
    "    save_best_only= True,\n",
    ")\n",
    "\n",
    "callbacks = [early_stop, reduce_lr, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054253a8",
   "metadata": {},
   "source": [
    "Where EarlyStopping decides when to stop, ReduceLROnPlateau decides how fast the model should keep learning.\n",
    "\n",
    "> What ``EarlyStopping`` does\n",
    "\n",
    "- It monitors ``val_loss`` every epoch. If ``val_loss`` does not improve for patience consecutive epochs (``patience=8``), training stops early. It restores the best weights seen during training (``restore_best_weights=True``), not the weights from the final epoch.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "> What ``ReduceLROnPlateau`` does\n",
    "\n",
    "- ``ReduceLROnPlateau`` is the adaptive learning‑rate  controller. It watches a metric — in our case \"``val_loss``\" — and if that metric stops improving for a certain number of epochs (``patience=5``), it reduces the learning rate by a factor (``factor=0.2``). \\\n",
    "So with our settings:\n",
    "  - If validation loss does not improve for 4 epochs then the learning rate becomes\n",
    "  $$\n",
    "  \\text{new\\_lr} = 0.2 \\cdot \\text{old\\_lr}\n",
    "  $$\n",
    "  It keeps doing this until it reaches the minimum allowed learning rate (``min_lr=1e-6``).\n",
    "\n",
    "<br><br>\n",
    "\n",
    "> What ``ModelCheckpoint`` does\n",
    "\n",
    "ModelCheckpoint is our automatic model saver.\n",
    "\n",
    "It monitors the metric ``val_loss``. Every time ``val_loss`` reaches a new minimum, it saves the model to disk. It overwrites the previous checkpoint so we always keep the best model, not the last one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f0359b",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97006a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== Training Overview ======================\n",
    "\n",
    "print(\n",
    "    f\"\\n\"\n",
    "    f\"================ Training Hyperparameters ================\\n\"\n",
    "    f\"  Device:                   {device}\\n\"\n",
    "    f\"  n_classes (train):        {train_generator.num_classes}\\n\"\n",
    "    f\"  n_classes (validation):   {val_generator.num_classes}\\n\"\n",
    "    f\"  Image Size:               ({img_w}, {img_h})\\n\"\n",
    "    f\"  n_channels:               {n_channels}\\n\"\n",
    "    f\"  batch_size:               {batch_size}\\n\"\n",
    "    f\"  steps_per_epoch:          {steps_per_epoch}\\n\"\n",
    "    f\"  validation_steps:         {validation_steps}\\n\"\n",
    "    f\"  n_epochs:                 {n_epochs}\\n\"\n",
    "    f\"  learning_rate:            {lr}\\n\"\n",
    "    f\"==========================================================\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Model Training ====\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs= n_epochs,\n",
    "    steps_per_epoch= steps_per_epoch,\n",
    "    validation_data= val_generator,\n",
    "    validation_steps= validation_steps,\n",
    "    callbacks= [early_stop, reduce_lr, checkpoint],\n",
    "    verbose= 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216af02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"tf_model.keras\")\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "\n",
    "print(\"Validation accuracy:\", val_acc)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
